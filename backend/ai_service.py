import json
import urllib.request
import urllib.error
from typing import Dict, Any

OLLAMA_URL = "http://127.0.0.1:11434/api/generate"
MODEL_NAME = "llama3.2:3b"

def generate_rri_report(agniveer_name: str, rri_data: Dict[str, Any]) -> str:
    """
    Generates a performance summary and retention report using Ollama.
    """
    
    # Construct Prompt
    prompt = f"""
    Role: You are the Company Commander's Second-in-Command (2IC).
    Task: specific patterns in the provided data.
    
    STRICT CONSTRAINTS:
    1. ONLY use the data provided below. Do NOT invent personal details (e.g., marriage, leave, family issues) unless explicitly stated.
    2. If a data point is missing, state "No data available".
    3. Every insight must be backed by a specific score or number from the profile.

    Soldier Profile:
    - Name: {agniveer_name}
    - RRI Score: {rri_data.get('rri_score')}/100 (Band: {rri_data.get('retention_band')})
    - Technical Competency: {rri_data.get('technical_component')}/50. Breakdown: {rri_data.get('technical_breakdown')}
    - Behavioral Attributes: {rri_data.get('behavioral_component')}/30. Status: {rri_data.get('behavioral_status')}. Trend: {rri_data.get('behavioral_trend')}
    - Achievements: {rri_data.get('achievement_component')}/20. Count: {rri_data.get('achievement_count')}

    Briefing Format:
    1. SITUATION: One factual sentence on current RRI standing.
    2. DATA-DRIVEN INSIGHTS:
       - [Insight 1]: (Cited Data Point)
       - [Insight 2]: (Cited Data Point)
    3. COMMAND CONSIDERATIONS: One logical inference based ONLY on the scores (e.g., "High technical but low behavioral suggests need for mentorship").
    
    Tone: Objective, factual, concise.
    """

    payload = {
        "model": MODEL_NAME,
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": 0.3, # Lower temperature for more deterministic/factual output
            "num_predict": 400
        }
    }

    try:
        data = json.dumps(payload).encode("utf-8")
        req = urllib.request.Request(
            OLLAMA_URL, 
            data=data, 
            headers={"Content-Type": "application/json"}
        )
        
        with urllib.request.urlopen(req) as response:
            if response.status == 200:
                result = json.loads(response.read().decode("utf-8"))
                return result.get("response", "No response generated by AI.")
            else:
                return f"Error: Ollama returned status {response.status}"
                
    except urllib.error.URLError as e:
        return f"Connection Failed: Ensure Ollama is running at {OLLAMA_URL}. details: {str(e)}"
    except Exception as e:
        return f"AI Generation Failed: {str(e)}"
